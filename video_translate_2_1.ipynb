{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjz+PzgjbyvNR98CdCb+ox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VGCH/video_translate/blob/main/video_translate_2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14aiZy0oV52y"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchaudio soundfile librosa openai-whisper transformers sentencepiece moviepy sacremoses\n",
        "!pip install -q silero num2words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import whisper\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "from google.colab import files\n",
        "from num2words import num2words as num2words_lib\n",
        "from silero import silero_tts"
      ],
      "metadata": {
        "id": "aduyVa7qWGh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")"
      ],
      "metadata": {
        "id": "iMtr4Bg-WLNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞ –≤ Colab\n",
        "def upload_video_file():\n",
        "    print(\"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"–ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {filename}\")\n",
        "        return filename\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "ba3x2Sv7WPeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ\n",
        "def extract_audio_from_video(video_path, audio_output='audio_original.wav'):\n",
        "    try:\n",
        "        # –ò—Å–ø–æ–ª—å–∑—É–µ–º moviepy –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ\n",
        "        from moviepy.editor import VideoFileClip\n",
        "\n",
        "        print(\"–ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ...\")\n",
        "        video = VideoFileClip(video_path)\n",
        "        audio = video.audio\n",
        "        audio.write_audiofile(audio_output, fps=44100, verbose=False, logger=None)\n",
        "        video.close()\n",
        "\n",
        "        print(f\"–ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫: {audio_output}\")\n",
        "        return audio_output\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∞—É–¥–∏–æ: {e}\")\n",
        "        # –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ ffmpeg\n",
        "        import subprocess\n",
        "        try:\n",
        "            subprocess.run([\n",
        "                'ffmpeg', '-i', video_path, '-q:a', '0', '-map', 'a',\n",
        "                audio_output, '-y'\n",
        "            ], check=True, capture_output=True)\n",
        "            return audio_output\n",
        "        except:\n",
        "            print(\"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "E9gZulURWTin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏\n",
        "def transcribe_with_timestamps(audio_path):\n",
        "    print(\"–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper...\")\n",
        "    model = whisper.load_model(\"medium\")  # –∏–ª–∏ \"small\", \"medium\", \"large\", \"base\"\n",
        "\n",
        "    print(\"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ...\")\n",
        "    result = model.transcribe(audio_path, word_timestamps=True, language='en')\n",
        "\n",
        "    segments = []\n",
        "    for segment in result['segments']:\n",
        "        segments.append({\n",
        "            'start': segment['start'],\n",
        "            'end': segment['end'],\n",
        "            'text': segment['text'].strip(),\n",
        "            'words': segment.get('words', [])\n",
        "        })\n",
        "\n",
        "    print(f\"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–æ {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤\")\n",
        "    return segments"
      ],
      "metadata": {
        "id": "6WrLW7VqWYAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. –ü–µ—Ä–µ–≤–æ–¥—á–∏–∫\n",
        "class Translator:\n",
        "    def __init__(self):\n",
        "        print(\"–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–æ–¥–∞...\")\n",
        "        self.model_name = \"Helsinki-NLP/opus-mt-en-ru\"\n",
        "        self.tokenizer = MarianTokenizer.from_pretrained(self.model_name)\n",
        "        self.model = MarianMTModel.from_pretrained(self.model_name).to(device)\n",
        "\n",
        "    def translate_text(self, text):\n",
        "        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤\n",
        "        text = ' '.join(text.split())\n",
        "        if not text or len(text.strip()) == 0:\n",
        "            return \"\"\n",
        "\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(**inputs, max_length=512)\n",
        "\n",
        "        translated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return translated\n",
        "\n",
        "    def translate_segments(self, segments):\n",
        "        print(\"–ü–µ—Ä–µ–≤–æ–¥–∏–º —Å–µ–≥–º–µ–Ω—Ç—ã...\")\n",
        "        translated_segments = []\n",
        "\n",
        "        for i, segment in enumerate(segments):\n",
        "            if not segment['text'].strip():\n",
        "                continue\n",
        "\n",
        "            print(f\"–ü–µ—Ä–µ–≤–æ–¥–∏–º —Å–µ–≥–º–µ–Ω—Ç {i+1}/{len(segments)}: {segment['text'][:50]}...\")\n",
        "            translated_text = self.translate_text(segment['text'])\n",
        "\n",
        "            translated_segments.append({\n",
        "                'start': segment['start'],\n",
        "                'end': segment['end'],\n",
        "                'original_text': segment['text'],\n",
        "                'translated_text': translated_text,\n",
        "                'duration': segment['end'] - segment['start']\n",
        "            })\n",
        "\n",
        "        return translated_segments"
      ],
      "metadata": {
        "id": "YVdUJrIdWb1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.  –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞\n",
        "class SileroTTSWithTiming:\n",
        "    def __init__(self):\n",
        "        print(\"–ó–∞–≥—Ä—É–∂–∞–µ–º Silero TTS...\")\n",
        "        self.model, _ = silero_tts(language='ru', speaker='v5_ru')\n",
        "        self.model.to(device)\n",
        "        self.sample_rate = 48000\n",
        "        print(\"–ì–æ—Ç–æ–≤\")\n",
        "\n",
        "    def preprocess_text(self, text: str) -> str:\n",
        "        \"\"\"–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º num2words\"\"\"\n",
        "\n",
        "        def convert_numbers(match):\n",
        "            \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —á–∏—Å–ª–∞ –≤ —Å–ª–æ–≤–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\"\"\"\n",
        "            num_str = match.group()\n",
        "\n",
        "            try:\n",
        "                # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ\n",
        "                num = float(num_str) if '.' in num_str else int(num_str)\n",
        "\n",
        "                # –û–°–û–ë–´–ô –°–õ–£–ß–ê–ô: –ì–û–î–ê (4-–∑–Ω–∞—á–Ω—ã–µ —á–∏—Å–ª–∞)\n",
        "                if len(num_str) == 4 and 1000 <= num <= 2099:\n",
        "                    # –ì–æ–¥–∞ –ø—Ä–æ–∏–∑–Ω–æ—Å–∏–º –ø–æ —Ü–∏—Ñ—Ä–∞–º: 2024 ‚Üí \"–¥–≤–∞ –Ω–æ–ª—å –¥–≤–∞ —á–µ—Ç—ã—Ä–µ\"\n",
        "                    digits = {\n",
        "                        '0': '–Ω–æ–ª—å', '1': '–æ–¥–∏–Ω', '2': '–¥–≤–∞', '3': '—Ç—Ä–∏',\n",
        "                        '4': '—á–µ—Ç—ã—Ä–µ', '5': '–ø—è—Ç—å', '6': '—à–µ—Å—Ç—å', '7': '—Å–µ–º—å',\n",
        "                        '8': '–≤–æ—Å–µ–º—å', '9': '–¥–µ–≤—è—Ç—å'\n",
        "                    }\n",
        "                    return ' '.join(digits[digit] for digit in num_str)\n",
        "\n",
        "                # –û–°–û–ë–´–ô –°–õ–£–ß–ê–ô: –ù–û–ú–ï–†–ê –¢–ï–õ–ï–§–û–ù–û–í, –ö–û–î–´ (6-12 —Ü–∏—Ñ—Ä)\n",
        "                if len(num_str) in [6, 7, 8, 10, 11, 12]:\n",
        "                    # –ü—Ä–æ–∏–∑–Ω–æ—Å–∏–º –ø–æ —Ü–∏—Ñ—Ä–∞–º\n",
        "                    digits = {\n",
        "                        '0': '–Ω–æ–ª—å', '1': '–æ–¥–∏–Ω', '2': '–¥–≤–∞', '3': '—Ç—Ä–∏',\n",
        "                        '4': '—á–µ—Ç—ã—Ä–µ', '5': '–ø—è—Ç—å', '6': '—à–µ—Å—Ç—å', '7': '—Å–µ–º—å',\n",
        "                        '8': '–≤–æ—Å–µ–º—å', '9': '–¥–µ–≤—è—Ç—å'\n",
        "                    }\n",
        "                    return ' '.join(digits[digit] for digit in num_str)\n",
        "\n",
        "                # –û–ë–´–ß–ù–´–ï –ß–ò–°–õ–ê: –∏—Å–ø–æ–ª—å–∑—É–µ–º num2words\n",
        "                # –î–ª—è –¥—Ä–æ–±–Ω—ã—Ö —á–∏—Å–µ–ª\n",
        "                if '.' in num_str:\n",
        "                    whole_part = num2words_lib(int(num), lang='ru')\n",
        "                    decimal_part = ' '.join(digits.get(d, d) for d in num_str.split('.')[1])\n",
        "                    return f\"{whole_part} —Ü–µ–ª—ã—Ö {decimal_part}\"\n",
        "\n",
        "                # –î–ª—è —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª\n",
        "                return num2words_lib(num, lang='ru')\n",
        "\n",
        "            except (ValueError, OverflowError):\n",
        "                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å\n",
        "                return num_str\n",
        "\n",
        "        # –®–∞–≥ 1: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≥–æ–¥ (–æ—Å–æ–±—ã–π —Å–ª—É—á–∞–π)\n",
        "        text = re.sub(r'\\b(19|20)\\d{2}\\b', convert_numbers, text)\n",
        "\n",
        "        # –®–∞–≥ 2: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –Ω–æ–º–µ—Ä–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ (6-12 —Ü–∏—Ñ—Ä –ø–æ–¥—Ä—è–¥)\n",
        "        text = re.sub(r'\\b\\d{6,12}\\b', convert_numbers, text)\n",
        "\n",
        "        # –®–∞–≥ 3: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—ã—á–Ω—ã–µ —á–∏—Å–ª–∞\n",
        "        text = re.sub(r'\\b\\d+(?:\\.\\d+)?\\b', convert_numbers, text)\n",
        "\n",
        "        # –®–∞–≥ 4: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π\n",
        "        replacements = {\n",
        "            '%': ' –ø—Ä–æ—Ü–µ–Ω—Ç',\n",
        "            '$': ' –¥–æ–ª–ª–∞—Ä',\n",
        "            '‚Ç¨': ' –µ–≤—Ä–æ',\n",
        "            '‚ÇΩ': ' —Ä—É–±–ª—å',\n",
        "            '¬£': ' —Ñ—É–Ω—Ç',\n",
        "            '¬•': ' –∏–µ–Ω–∞',\n",
        "            '+': ' –ø–ª—é—Å',\n",
        "            '*': ' —É–º–Ω–æ–∂–∏—Ç—å –Ω–∞',\n",
        "            '√∑': ' —Ä–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞',\n",
        "            '=': ' —Ä–∞–≤–Ω–æ',\n",
        "            '/': ' –Ω–∞',\n",
        "            '>': ' –±–æ–ª—å—à–µ',\n",
        "            '<': ' –º–µ–Ω—å—à–µ'\n",
        "        }\n",
        "\n",
        "        for char, replacement in replacements.items():\n",
        "            text = text.replace(char, replacement)\n",
        "\n",
        "        # –®–∞–≥ 5: –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ —á–∏—Å–µ–ª\n",
        "        text = re.sub(r'(\\d+)\\s*–ø—Ä–æ—Ü–µ–Ω—Ç', r'\\1 –ø—Ä–æ—Ü–µ–Ω—Ç', text)\n",
        "\n",
        "        # –®–∞–≥ 6: –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞–ª—é—Ç –ø–æ—Å–ª–µ —á–∏—Å–µ–ª\n",
        "        text = re.sub(r'(\\d+)\\s*(–¥–æ–ª–ª–∞—Ä|–µ–≤—Ä–æ|—Ä—É–±–ª—å|—Ñ—É–Ω—Ç|–∏–µ–Ω–∞)', r'\\1 \\2', text)\n",
        "\n",
        "        # –®–∞–≥ 7: –û—á–∏—Å—Ç–∫–∞ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤\n",
        "        text = re.sub(r'[¬´¬ª\"‚Äú‚Äù‚Äû\\[\\]()]', '', text)\n",
        "\n",
        "        # –®–∞–≥ 8: –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        return text\n",
        "\n",
        "    def high_quality_speed_up(self, audio: np.ndarray, speed_factor: float) -> np.ndarray:\n",
        "        \"\"\"–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –£–°–ö–û–†–ï–ù–ò–ï (—Ç–æ–ª—å–∫–æ —É—Å–∫–æ—Ä–µ–Ω–∏–µ, –±–µ–∑ –∑–∞–º–µ–¥–ª–µ–Ω–∏—è!)\"\"\"\n",
        "        if abs(speed_factor - 1.0) < 0.01 or speed_factor < 1.0:\n",
        "            return audio  # –ù–µ –∑–∞–º–µ–¥–ª—è–µ–º!\n",
        "\n",
        "        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞\n",
        "        if speed_factor > 2.0:\n",
        "            print(f\"  –í–Ω–∏–º–∞–Ω–∏–µ: –±–æ–ª—å—à–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ {speed_factor:.2f}x, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 2.0x\")\n",
        "            speed_factor = 2.0\n",
        "\n",
        "        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞\n",
        "        n_fft = 2048\n",
        "        hop_length = n_fft // 4\n",
        "\n",
        "        try:\n",
        "            # STFT –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\n",
        "            stft = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length, window='hann')\n",
        "\n",
        "            # Phase vocoder –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
        "            stft_stretched = librosa.phase_vocoder(stft, rate=speed_factor, hop_length=hop_length)\n",
        "\n",
        "            # –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\n",
        "            audio_stretched = librosa.istft(stft_stretched, hop_length=hop_length, window='hann')\n",
        "\n",
        "            return audio_stretched.astype(np.float32)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  –û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å–∫–æ—Ä–µ–Ω–∏–∏: {e}\")\n",
        "            # –†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ - –æ–±—Ä–µ–∑–∫–∞\n",
        "            target_samples = int(len(audio) / speed_factor)\n",
        "            return audio[:target_samples]\n",
        "\n",
        "    def apply_smooth_fade(self, audio: np.ndarray, fade_in_ms: int = 5, fade_out_ms: int = 10) -> np.ndarray:\n",
        "        \"\"\"–ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–ª–∞–≤–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —â–µ–ª—á–∫–æ–≤\"\"\"\n",
        "        if len(audio) < 100:  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è —Ñ–µ–π–¥–æ–≤\n",
        "            return audio\n",
        "\n",
        "        # Fade-in –≤ –Ω–∞—á–∞–ª–µ\n",
        "        fade_in_samples = int(fade_in_ms * self.sample_rate / 1000)\n",
        "        if fade_in_samples > 0 and len(audio) > fade_in_samples:\n",
        "            fade_in = np.linspace(0, 1, fade_in_samples)\n",
        "            audio[:fade_in_samples] *= fade_in\n",
        "\n",
        "        # Fade-out –≤ –∫–æ–Ω—Ü–µ\n",
        "        fade_out_samples = int(fade_out_ms * self.sample_rate / 1000)\n",
        "        if fade_out_samples > 0 and len(audio) > fade_out_samples:\n",
        "            fade_out = np.linspace(1, 0, fade_out_samples)\n",
        "            audio[-fade_out_samples:] *= fade_out\n",
        "\n",
        "        return audio\n",
        "\n",
        "    def trim_excessive_silence(self, audio: np.ndarray, threshold_db: float = -30) -> np.ndarray:\n",
        "        \"\"\"–£–±–∏—Ä–∞–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—É—é —Ç–∏—à–∏–Ω—É –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ\"\"\"\n",
        "        if len(audio) == 0:\n",
        "            return audio\n",
        "\n",
        "        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ dB\n",
        "        audio_db = librosa.amplitude_to_db(np.abs(audio), ref=np.max)\n",
        "\n",
        "        # –ù–∞—Ö–æ–¥–∏–º –Ω–µ–Ω—É–ª–µ–≤—ã–µ —É—á–∞—Å—Ç–∫–∏ (–≥–¥–µ –≥—Ä–æ–º–∫–æ—Å—Ç—å –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞)\n",
        "        above_threshold = audio_db > threshold_db\n",
        "\n",
        "        if not np.any(above_threshold):\n",
        "            return audio[:int(0.1 * self.sample_rate)]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ—Ä–æ—Ç–∫—É—é —Ç–∏—à–∏–Ω—É\n",
        "\n",
        "        # –ù–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü —Ä–µ—á–∏\n",
        "        speech_start = np.argmax(above_threshold)\n",
        "        speech_end = len(audio) - np.argmax(above_threshold[::-1])\n",
        "\n",
        "        # –û—Å—Ç–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–∏–µ –ø–∞—É–∑—ã (50–º—Å) –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ\n",
        "        padding = int(0.05 * self.sample_rate)\n",
        "        start = max(0, speech_start - padding)\n",
        "        end = min(len(audio), speech_end + padding)\n",
        "\n",
        "        return audio[start:end]\n",
        "\n",
        "    def generate_audio_segment(self, text: str, target_duration: float) -> np.ndarray:\n",
        "        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "        original_text = text\n",
        "\n",
        "        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
        "        text = self.preprocess_text(text.strip())\n",
        "\n",
        "        if not text or len(text) < 2:\n",
        "            print(f\"  –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∏—à–∏–Ω—É\")\n",
        "            return np.zeros(int(target_duration * self.sample_rate), dtype=np.float32)\n",
        "\n",
        "        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
        "        print(f\"  –û—Ä–∏–≥–∏–Ω–∞–ª: {original_text[:80]}...\")\n",
        "        print(f\"  –û–±—Ä–∞–±–æ—Ç–∞–Ω: {text[:80]}...\")\n",
        "\n",
        "        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "        if len(text) > 350:\n",
        "            print(f\"  –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤), –æ–±—Ä–µ–∑–∞–µ–º\")\n",
        "            text = text[:340] + \"...\"\n",
        "\n",
        "        try:\n",
        "            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ\n",
        "            with torch.no_grad():\n",
        "                wav = self.model.apply_tts(\n",
        "                    text=text,\n",
        "                    speaker='xenia',\n",
        "                    sample_rate=self.sample_rate,\n",
        "                    put_accent=True,\n",
        "                    put_yo=True\n",
        "                )\n",
        "\n",
        "            audio = wav.cpu().numpy().squeeze()\n",
        "\n",
        "            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω—é—é —Ç–∏—à–∏–Ω—É –ø–æ –∫—Ä–∞—è–º\n",
        "            audio = self.trim_excessive_silence(audio)\n",
        "\n",
        "            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "            if np.max(np.abs(audio)) > 0:\n",
        "                audio = audio / np.max(np.abs(audio)) * 0.95\n",
        "\n",
        "            # –¢–µ–∫—É—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
        "            current_duration = len(audio) / self.sample_rate\n",
        "            print(f\"  –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ: {current_duration:.2f}s\")\n",
        "            print(f\"  –¶–µ–ª–µ–≤–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {target_duration:.2f}s\")\n",
        "\n",
        "            # –†–ï–®–ê–ï–ú: —á—Ç–æ –¥–µ–ª–∞—Ç—å —Å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é?\n",
        "            if current_duration > target_duration:\n",
        "                # –°–ª—É—á–∞–π 1: —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –î–õ–ò–ù–ù–ï–ï - –£–°–ö–û–†–Ø–ï–ú\n",
        "                speed_factor = current_duration / target_duration\n",
        "                print(f\"  –†—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–Ω–µ–µ, —É—Å–∫–æ—Ä—è–µ–º –≤ {speed_factor:.2f} —Ä–∞–∑\")\n",
        "                audio = self.high_quality_speed_up(audio, speed_factor)\n",
        "                current_duration = len(audio) / self.sample_rate\n",
        "                print(f\"  –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ —É—Å–∫–æ—Ä–µ–Ω–∏—è: {current_duration:.2f}s\")\n",
        "\n",
        "            # –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –¥–ª–∏–Ω—ã\n",
        "            target_samples = int(target_duration * self.sample_rate)\n",
        "\n",
        "            if len(audio) > target_samples:\n",
        "                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —É—Å–∫–æ—Ä–µ–Ω–∏—è –≤—Å–µ –µ—â–µ –¥–ª–∏–Ω–Ω–µ–µ - –æ–±—Ä–µ–∑–∞–µ–º —Å fade-out\n",
        "                excess_samples = len(audio) - target_samples\n",
        "                print(f\"  –ü–æ—Å–ª–µ —É—Å–∫–æ—Ä–µ–Ω–∏—è –≤—Å–µ –µ—â–µ –¥–ª–∏–Ω–Ω–µ–µ, –æ–±—Ä–µ–∑–∞–µ–º {excess_samples} —Å—ç–º–ø–ª–æ–≤\")\n",
        "\n",
        "                # –ü—Ä–∏–º–µ–Ω—è–µ–º fade-out –ø–µ—Ä–µ–¥ –æ–±—Ä–µ–∑–∫–æ–π\n",
        "                fade_out_samples = min(100, excess_samples)\n",
        "                if fade_out_samples > 0:\n",
        "                    audio[target_samples - fade_out_samples:target_samples] *= np.linspace(1, 0, fade_out_samples)\n",
        "\n",
        "                audio = audio[:target_samples]\n",
        "\n",
        "            elif len(audio) < target_samples:\n",
        "                # –°–ª—É—á–∞–π 2: —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –ö–û–†–û–ß–ï - –ü–†–û–°–¢–û –î–û–ë–ê–í–õ–Ø–ï–ú –¢–ò–®–ò–ù–£\n",
        "                silence_samples = target_samples - len(audio)\n",
        "                silence_duration = silence_samples / self.sample_rate\n",
        "                print(f\"  –†—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—á–µ, –¥–æ–±–∞–≤–ª—è–µ–º {silence_duration:.2f}s —Ç–∏—à–∏–Ω—ã\")\n",
        "\n",
        "                # –ü—Ä–æ—Å—Ç–æ –¥–æ–ø–æ–ª–Ω—è–µ–º —Ç–∏—à–∏–Ω–æ–π –≤ –∫–æ–Ω—Ü–µ\n",
        "                audio = np.pad(audio, (0, silence_samples), mode='constant')\n",
        "\n",
        "            else:\n",
        "                # –ò–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥–æ—à–ª–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏\n",
        "                print(f\"  –ò–¥–µ–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å! ¬±0.01s\")\n",
        "\n",
        "            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–ª–∞–≤–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã\n",
        "            audio = self.apply_smooth_fade(audio, fade_in_ms=5, fade_out_ms=10)\n",
        "\n",
        "            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞\n",
        "            final_duration = len(audio) / self.sample_rate\n",
        "            duration_diff = abs(final_duration - target_duration)\n",
        "\n",
        "            if duration_diff > 0.01:\n",
        "                print(f\"  –í–Ω–∏–º–∞–Ω–∏–µ: –∏—Ç–æ–≥–æ–≤–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –Ω–∞ {duration_diff:.3f}s\")\n",
        "            else:\n",
        "                print(f\"  –ò—Ç–æ–≥–æ–≤–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {final_duration:.2f}s (—Ü–µ–ª—å: {target_duration:.2f}s)\")\n",
        "\n",
        "            return audio.astype(np.float32)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}\")\n",
        "            return np.zeros(int(target_duration * self.sample_rate), dtype=np.float32)"
      ],
      "metadata": {
        "id": "WBuCOx36WhFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ\n",
        "def create_final_audio(translated_segments, tts, original_audio_duration):\n",
        "    print(\"–°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ...\")\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ\n",
        "    final_audio = np.zeros(int(original_audio_duration * tts.sample_rate), dtype=np.float32)\n",
        "    processed_segments = 0\n",
        "\n",
        "    for i, segment in enumerate(translated_segments):\n",
        "        print(f\"–°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç {i+1}/{len(translated_segments)}: '{segment['translated_text'][:50]}...'\")\n",
        "\n",
        "        try:\n",
        "            synthesized_audio = tts.generate_audio_segment(\n",
        "                segment['translated_text'],\n",
        "                segment['duration']\n",
        "            )\n",
        "\n",
        "            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ –≤–∞–ª–∏–¥–Ω–æ\n",
        "            if synthesized_audio is None or len(synthesized_audio) == 0:\n",
        "                print(f\"–ü—É—Å—Ç–æ–µ –∞—É–¥–∏–æ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ {i+1}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º\")\n",
        "                continue\n",
        "\n",
        "            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º –∞—É–¥–∏–æ\n",
        "            start_sample = int(segment['start'] * tts.sample_rate)\n",
        "            end_sample = start_sample + len(synthesized_audio)\n",
        "\n",
        "            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã\n",
        "            if start_sample >= len(final_audio):\n",
        "                print(f\"–°–µ–≥–º–µ–Ω—Ç {i+1} –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º\")\n",
        "                continue\n",
        "\n",
        "            if end_sample > len(final_audio):\n",
        "                print(f\"–°–µ–≥–º–µ–Ω—Ç {i+1} –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã, –æ–±—Ä–µ–∑–∞–µ–º\")\n",
        "                synthesized_audio = synthesized_audio[:len(final_audio) - start_sample]\n",
        "                end_sample = len(final_audio)\n",
        "\n",
        "            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ\n",
        "            final_audio[start_sample:end_sample] = synthesized_audio\n",
        "            processed_segments += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–µ–≥–º–µ–Ω—Ç–∞ {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_segments}/{len(translated_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤\")\n",
        "    return final_audio"
      ],
      "metadata": {
        "id": "Pqas5hBQWplr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å\n",
        "def process_video_file():\n",
        "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∏–¥–µ–æ—Ñ–∞–π–ª\n",
        "    video_path = upload_video_file()\n",
        "    if not video_path:\n",
        "        print(\"–§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
        "        return\n",
        "\n",
        "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ\n",
        "    audio_path = extract_audio_from_video(video_path)\n",
        "    if not audio_path or not os.path.exists(audio_path):\n",
        "        print(\"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ\")\n",
        "        return\n",
        "\n",
        "    # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ\n",
        "    try:\n",
        "        original_audio, orig_sr = librosa.load(audio_path, sr=None)\n",
        "        original_duration = len(original_audio) / orig_sr\n",
        "        print(f\"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ: {original_duration:.2f} —Å–µ–∫—É–Ω–¥\")\n",
        "    except Exception as e:\n",
        "        print(f\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ: {e}\")\n",
        "        return\n",
        "\n",
        "    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º\n",
        "    segments = transcribe_with_timestamps(audio_path)\n",
        "    if not segments:\n",
        "        print(\"–ù–µ —É–¥–∞–ª–æ—Å—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ\")\n",
        "        return\n",
        "\n",
        "    # –ü–µ—Ä–µ–≤–æ–¥–∏–º\n",
        "    translator = Translator()\n",
        "    translated_segments = translator.translate_segments(segments)\n",
        "    if not translated_segments:\n",
        "        print(\"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ —Å–µ–≥–º–µ–Ω—Ç—ã\")\n",
        "        return\n",
        "\n",
        "    # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å\n",
        "    tts = SileroTTSWithTiming()\n",
        "    final_audio = create_final_audio(translated_segments, tts, original_duration)\n",
        "\n",
        "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
        "    output_path = 'translated_audio.wav'\n",
        "    sf.write(output_path, final_audio, tts.sample_rate)\n",
        "\n",
        "    print(f\"–ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_path}\")\n",
        "    print(f\"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {os.path.getsize(output_path) / (1024*1024):.2f} MB\")\n",
        "\n",
        "    # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º —Å–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
        "    print(\"–°–∫–∞—á–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç...\")\n",
        "    files.download(output_path)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å\n",
        "print(\"–ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ...\")\n",
        "result = process_video_file()\n",
        "\n",
        "if result:\n",
        "    print(\"üéâ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!\")\n",
        "else:\n",
        "    print(\"‚ùå –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–∞–º–∏\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vf55N1KDWufb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü—Ä–æ–±–Ω—ã–π —Ç–µ—Å—Ç —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "model_id = 'v5_cis_base'\n",
        "model, example_text = silero_tts(language='ru',\n",
        "                                 speaker=model_id)\n",
        "model.to(device)\n",
        "\n",
        "sample_rate = 48000\n",
        "speaker = 'ru_alexandr'\n",
        "'''\n",
        "–¥–æ—Å—Ç—É–ø–Ω—ã–µ –≥–æ–ª–æ—Å–∞\n",
        "\n",
        "should be in bak_aigul, ru_aigul, tat_albina, ru_albina, erz_alexandr,\n",
        "ru_alexandr, bak_alfia, ru_alfia, bak_alfia2, ru_alfia2, bel_anatoliy,\n",
        "udm_bogdan, ru_bogdan, bel_dmitriy, ru_dmitriy, chv_ekaterina, ru_ekaterina,\n",
        "kat_vika, ru_vika, aze_gamat, ru_gamat, ukr_igor, ru_igor, kjh_karina,\n",
        "ru_karina, xal_kejilgan, ru_kejilgan, xal_kermen, ru_kermen, bel_larisa,\n",
        "tat_marat, ru_marat, bak_miyau, ru_miyau, kir_nurgul, ru_nurgul, mdf_oksana,\n",
        "ru_oksana, tgk_onaoy, ru_onaoy, bak_ramilia, ru_ramilia, ukr_roman, ru_roman,\n",
        "tgk_safarhuja, ru_safarhuja, uzb_saida, ru_saida, kjh_sibday, ru_sibday,\n",
        "hye_zara, ru_zara, kaz_zhadyra, ru_zhadyra, kaz_zhazira, ru_zhazira,\n",
        "sah_zinaida, ru_zinaida, ru_eduard, kbd_eduard\n",
        "'''\n",
        "\n",
        "example_text = '–±—Ä–æ–¥+–∏—Ç—å —Å –¥–æ–∂–¥—ë–º –ø–æ–¥ –æ–∫–Ω–∞–º–∏ —Ç–≤–æ–∏–º–∏.'\n",
        "\n",
        "audio = model.apply_tts(text=example_text,\n",
        "                        speaker=speaker,\n",
        "                        sample_rate=sample_rate)\n",
        "print(example_text)\n",
        "display(Audio(audio, rate=sample_rate))"
      ],
      "metadata": {
        "id": "Q6K7oeWVQ4mM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}